{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Conceito</h1>\n",
    "\n",
    "<h2>Aleatoriedade inicial</h2>\n",
    "\n",
    "Os modelos de *machine learning* estão sujeitos à uma aleatoriedade inicial, principalmente pela maneira como os dados de treino e teste são divididos, mas também em alguns casos devido aos próprios modelos. Por exemplo:\n",
    "\n",
    "- **Divisão treino/teste**: o módulo *train_test_split* do *SKLearn* divide os pontos de dados em treino e teste de maneira aleatória, 'embaralhando' os mesmos antes da divisão\n",
    "- **Árvores de decisão**: em cada divisão as características são permutadas de maneira aleatória\n",
    "- **Máquina de vetor de suporte**: pode 'embaralhar' aleatóriamente os pontos de dados de treinos, o que eventualmente resultará em vetores diferentes\n",
    "\n",
    "Devido à isso, a técnica de *holdout* (separar a base de dados em dados de treino e dados de teste que serão usados para validação do modelo) é sujeita à interferência dessa aleatóriedade inicial, podendo apresentar diferentes resultados. Portanto, é importante definir outro método de validação dos modelos, que possa fornecer um intervalo para as métricas como acurácia, precisão etc.\n",
    "\n",
    "<h2>Validação Cruzada</h2>\n",
    "\n",
    "A validação cruzada consiste em dividir a base de dados de treino e teste em $n$ maneiras diferentes, e então realizando o procedimento de treino e teste para todas essas divisões. Então, através da média das métricas e do desvio padrão das mesas para essas amostras é possível definir um intervalo de confiança para cada uma delas.\n",
    "\n",
    "<h2><i>Splitters</i> do <i>SKLearn</i></h2>\n",
    "\n",
    "O método da biblioteca *SKLearn* que realiza a validação cruzada divide os dados sempre da mesma maneira. Por isso existem métodos na biblioteca que realizam essa divisão:\n",
    "\n",
    "- ***KFold***: divide os dados em $n$ partições consecutivas, podendo 'embaralhar' os dados caso isso seja específicado.\n",
    "- ***StratifiedKFold***: semelhante ao *KFold*, porém realiza a estratificação dos dados - ou seja, mantém as divisões com valores proporcionais de cada classe.\n",
    "- ***GroupKFold***: semelhante ao *KFold*, porém garante que todos os elementos de um mesmo grupo especificado se mantenham no mesma divisão (treino ou teste)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Prática</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lendo a base de dados a ser utilizada\n",
    "dados = pd.read_csv(r'Dados\\Base.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividindo inputs e outputs\n",
    "x = dados[[\"preco\", \"idade_do_modelo\", \"km_por_ano\"]].values\n",
    "y = dados[\"vendido\"].values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividindo treino e teste\n",
    "SEED = 158020\n",
    "np.random.seed(SEED)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.25,\n",
    "                                                         stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A acurácia do dummy stratified foi de  50.96\n"
     ]
    }
   ],
   "source": [
    "# Verificando a acurácia de um modelo dummy, para definição de uma baseline\n",
    "dummy_stratified = DummyClassifier(strategy='stratified')\n",
    "dummy_stratified.fit(x_train, y_train)\n",
    "acuracia = dummy_stratified.score(x_test, y_test) * 100\n",
    "\n",
    "print(f\"A acurácia do dummy stratified foi de {acuracia: .2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A acurácia foi  71.92\n"
     ]
    }
   ],
   "source": [
    "# Verificando a acurácia de um modelo de árvore de decisão:\n",
    "SEED = 158020\n",
    "np.random.seed(SEED)\n",
    "modelo_dtc1 = DecisionTreeClassifier(max_depth=2)\n",
    "modelo_dtc1.fit(x_train, y_train)\n",
    "previsoes_dtc1 = modelo_dtc1.predict(x_test)\n",
    "\n",
    "acuracia_dtc1 = accuracy_score(y_test, previsoes_dtc1) * 100\n",
    "print (f\"A acurácia foi {acuracia_dtc1: .2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A acurácia foi  76.84\n"
     ]
    }
   ],
   "source": [
    "# Verificando a acurácia do mesmo modelo para outro valor de SEED:\n",
    "\n",
    "SEED2 = 5\n",
    "np.random.seed(SEED2)\n",
    "\n",
    "x_train2, x_test2, y_train2, y_test2 = train_test_split(x, y, test_size = 0.25,\n",
    "                                                         stratify = y)\n",
    "\n",
    "modelo_dtc2 = DecisionTreeClassifier(max_depth=2)\n",
    "modelo_dtc2.fit(x_train2, y_train2)\n",
    "previsoes_dtc2 = modelo_dtc2.predict(x_test2)\n",
    "\n",
    "acuracia_dtc2 = accuracy_score(y_test2, previsoes_dtc2) * 100\n",
    "print (f\"A acurácia foi {acuracia_dtc2: .2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.01049924, 0.00950122, 0.01100016, 0.01000237, 0.00899577,\n",
       "        0.00999856, 0.01699901, 0.00899673, 0.0134995 , 0.00899839]),\n",
       " 'score_time': array([0.00150013, 0.00138736, 0.00101304, 0.00150061, 0.00300574,\n",
       "        0.00100255, 0.00151253, 0.00150251, 0.00100255, 0.00100064]),\n",
       " 'test_score': array([0.742, 0.77 , 0.749, 0.764, 0.761, 0.764, 0.754, 0.755, 0.759,\n",
       "        0.76 ])}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Agora verificando o desempenho do modelo através da validação cruzada\n",
    "SEED = 158020\n",
    "np.random.seed(SEED)\n",
    "\n",
    "modelo_dtc3 = DecisionTreeClassifier(max_depth=2)\n",
    "resultados = cross_validate(modelo_dtc3, x, y, cv=10)\n",
    "\n",
    "resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A acurácia com validação cruzada, para um nível de confiança de 95%, está entre 75.01% e 76.55%\n"
     ]
    }
   ],
   "source": [
    "# Considerando que o test_score possuí uma distribuição normal e que, sendo assim, 95% das ocorrências estarão dentro do intervalo\n",
    "# média - 2 desvios padrões e média + 2 desvios padrões, pode-se definir o intervalo da seguinte maneira:\n",
    "\n",
    "media = resultados['test_score'].mean()*100\n",
    "desvio_padrao = resultados['test_score'].std()*100\n",
    "\n",
    "print(f'A acurácia com validação cruzada, para um nível de confiança de 95%, está entre {media - desvio_padrao:.2f}% e {media + desvio_padrao:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A acurácia com validação cruzada, para um nível de confiança de 95%, está entre 75.01% e 76.55%\n"
     ]
    }
   ],
   "source": [
    "# Repetindo o teste para valores diferentes de SEED:\n",
    "\n",
    "# Agora verificando o desempenho do modelo através da validação cruzada\n",
    "SEED = 30\n",
    "np.random.seed(SEED)\n",
    "\n",
    "modelo_dtc4 = DecisionTreeClassifier(max_depth=2)\n",
    "resultados2 = cross_validate(modelo_dtc4, x, y, cv=10)\n",
    "\n",
    "media2 = resultados2['test_score'].mean()*100\n",
    "desvio_padrao2 = resultados2['test_score'].std()*100\n",
    "\n",
    "print(f'A acurácia com validação cruzada, para um nível de confiança de 95%, está entre {media2 - desvio_padrao2:.2f}% e {media2 + desvio_padrao2:.2f}%')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ou seja, utilizando a validação cruzada é possível reduzir a influência da aleatoriedade inicial. Porém, nos exemplos acima, foi removida a aleatoriedade da validação cruzada: o método está dividindo os dados sempre da mesma maneira. Para realizar o teste considerando aleatoriedade também nesta etapa, é possível utilizar o método Kfold:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A acurácia com validação cruzada e aleatorização através do KFold, para um nível de confiança de 95%, está entre 75.17% e 76.39%\n"
     ]
    }
   ],
   "source": [
    "# Utilizando o método KFold:\n",
    "\n",
    "cv = KFold(n_splits=10, shuffle=True)\n",
    "modelo_dtc5 = DecisionTreeClassifier(max_depth=2)\n",
    "resultados3 = cross_validate(modelo_dtc5, x, y, cv=cv)\n",
    "\n",
    "media3 = resultados3['test_score'].mean()*100\n",
    "desvio_padrao3 = resultados3['test_score'].std()*100\n",
    "\n",
    "print(f'A acurácia com validação cruzada e aleatorização através do KFold, para um nível de confiança de 95%, está entre {media3 - desvio_padrao3:.2f}% e {media3 + desvio_padrao3:.2f}%')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para garantir que os dados serão divididos de maneira estratificada (proporcional às classes), é possível utilizar o método KFold estratificado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A acurácia com validação cruzada e aleatorização através do StratifiedKFold, para um nível de confiança de 95%, está entre 74.66% e 76.90%\n"
     ]
    }
   ],
   "source": [
    "# Utilizando o método StratifiedKFold:\n",
    "\n",
    "cv2 = StratifiedKFold(n_splits=10, shuffle=True)\n",
    "modelo_dtc6 = DecisionTreeClassifier(max_depth=2)\n",
    "resultados4 = cross_validate(modelo_dtc6, x, y, cv=cv2)\n",
    "\n",
    "media4 = resultados4['test_score'].mean()*100\n",
    "desvio_padrao4 = resultados4['test_score'].std()*100\n",
    "\n",
    "print(f'A acurácia com validação cruzada e aleatorização através do StratifiedKFold, para um nível de confiança de 95%, está entre {media4 - desvio_padrao4:.2f}% e {media4 + desvio_padrao4:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
